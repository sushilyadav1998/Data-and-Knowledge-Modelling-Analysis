{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16e50443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e49673",
   "metadata": {},
   "source": [
    "## Question 5 \n",
    "### Loading Abalone dataset and printing the normalized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c090b0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.57455813, -0.43214879, -1.06442415, ..., -0.60768536,\n",
       "        -0.72621157, -0.63821689],\n",
       "       [-1.44898585, -1.439929  , -1.18397831, ..., -1.17090984,\n",
       "        -1.20522124, -1.21298732],\n",
       "       [ 0.05003309,  0.12213032, -0.10799087, ..., -0.4634999 ,\n",
       "        -0.35668983, -0.20713907],\n",
       "       ...,\n",
       "       [ 0.6329849 ,  0.67640943,  1.56576738, ...,  0.74855917,\n",
       "         0.97541324,  0.49695471],\n",
       "       [ 0.84118198,  0.77718745,  0.25067161, ...,  0.77334105,\n",
       "         0.73362741,  0.41073914],\n",
       "       [ 1.54905203,  1.48263359,  1.32665906, ...,  2.64099341,\n",
       "         1.78744868,  1.84048058]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load raw abalone dataset\n",
    "abalone_df = pd.read_csv(\"D:/UWaterloo/ece657a/Assignment 2/abalone.csv\", names = ['Sex', 'Length', 'Diameter', 'Height', 'Whole_weight', \n",
    "                      'Sucked_weight', 'Viscera_weight', 'Shell_weight', 'Rings'], sep = ',')\n",
    "\n",
    "# Separate indep and dep features\n",
    "X_abalone = abalone_df.iloc[:, 1:-1] # Removed the sex feature\n",
    "y_abalone = abalone_df.iloc[:, -1]\n",
    "\n",
    "# Normalize dataset \n",
    "sc1 = StandardScaler()\n",
    "X_abalone = sc1.fit_transform(X_abalone)\n",
    "X_abalone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe37b44",
   "metadata": {},
   "source": [
    "## Applying PCA as a pre-processing step on abalone dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca0d103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.756019</td>\n",
       "      <td>-0.390532</td>\n",
       "      <td>-0.329928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.362734</td>\n",
       "      <td>-0.105153</td>\n",
       "      <td>0.252264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.482338</td>\n",
       "      <td>0.252055</td>\n",
       "      <td>-0.443918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.509041</td>\n",
       "      <td>0.207608</td>\n",
       "      <td>-0.000519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.654006</td>\n",
       "      <td>-0.272819</td>\n",
       "      <td>0.275035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0.801361</td>\n",
       "      <td>0.385426</td>\n",
       "      <td>-0.064832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>0.719312</td>\n",
       "      <td>-0.329146</td>\n",
       "      <td>-0.293062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>2.167373</td>\n",
       "      <td>0.724010</td>\n",
       "      <td>0.402521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>1.647501</td>\n",
       "      <td>-0.305166</td>\n",
       "      <td>-0.306030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>4.894542</td>\n",
       "      <td>-0.705798</td>\n",
       "      <td>0.550942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PC1       PC2       PC3\n",
       "0    -1.756019 -0.390532 -0.329928\n",
       "1    -3.362734 -0.105153  0.252264\n",
       "2    -0.482338  0.252055 -0.443918\n",
       "3    -1.509041  0.207608 -0.000519\n",
       "4    -3.654006 -0.272819  0.275035\n",
       "...        ...       ...       ...\n",
       "4172  0.801361  0.385426 -0.064832\n",
       "4173  0.719312 -0.329146 -0.293062\n",
       "4174  2.167373  0.724010  0.402521\n",
       "4175  1.647501 -0.305166 -0.306030\n",
       "4176  4.894542 -0.705798  0.550942\n",
       "\n",
       "[4177 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply PCA on abalone dataset\n",
    "pca = PCA(n_components=3)\n",
    "abalone_pca = pca.fit_transform(X_abalone)\n",
    "abalone_pca_df = pd.DataFrame(data=abalone_pca, columns=['PC1', 'PC2', 'PC3'])\n",
    "abalone_pca_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e15446f",
   "metadata": {},
   "source": [
    "## Applying LDA as a pre-processing step on abalone dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71829bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rings</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.791003</td>\n",
       "      <td>-0.235208</td>\n",
       "      <td>0.359351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.355522</td>\n",
       "      <td>0.336978</td>\n",
       "      <td>0.214024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.766719</td>\n",
       "      <td>-0.246564</td>\n",
       "      <td>1.129422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.611434</td>\n",
       "      <td>0.098075</td>\n",
       "      <td>0.230542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.674301</td>\n",
       "      <td>0.527509</td>\n",
       "      <td>0.102575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.921330</td>\n",
       "      <td>-0.612381</td>\n",
       "      <td>-0.272399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.425796</td>\n",
       "      <td>-0.894428</td>\n",
       "      <td>-0.034727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.064523</td>\n",
       "      <td>-0.385654</td>\n",
       "      <td>-0.787231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.840757</td>\n",
       "      <td>-1.513723</td>\n",
       "      <td>-0.864217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.843580</td>\n",
       "      <td>0.352389</td>\n",
       "      <td>-2.262564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2\n",
       "Rings                              \n",
       "15    -0.791003 -0.235208  0.359351\n",
       "7     -2.355522  0.336978  0.214024\n",
       "9      0.766719 -0.246564  1.129422\n",
       "10    -0.611434  0.098075  0.230542\n",
       "7     -2.674301  0.527509  0.102575\n",
       "...         ...       ...       ...\n",
       "11     0.921330 -0.612381 -0.272399\n",
       "10     0.425796 -0.894428 -0.034727\n",
       "9      1.064523 -0.385654 -0.787231\n",
       "10     0.840757 -1.513723 -0.864217\n",
       "12     0.843580  0.352389 -2.262564\n",
       "\n",
       "[4177 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply LDA on raw abalone dataset\n",
    "X_abalone_lda = X_abalone\n",
    "y_abalone_lda = y_abalone\n",
    "lda = LinearDiscriminantAnalysis(n_components=3)\n",
    "X_abalone_lda = lda.fit(X_abalone_lda, y_abalone_lda).transform(X_abalone_lda)\n",
    "abalone_lda_df = pd.DataFrame(X_abalone_lda, y_abalone_lda)\n",
    "abalone_lda_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410b3d10",
   "metadata": {},
   "source": [
    "## Loading wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6688880c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>colour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.29</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0.044</td>\n",
       "      <td>62.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.42</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.66</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.046</td>\n",
       "      <td>26.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>8.6</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.034</td>\n",
       "      <td>15.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.36</td>\n",
       "      <td>11.4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.46</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.038</td>\n",
       "      <td>4.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.30</td>\n",
       "      <td>10.1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.66</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.046</td>\n",
       "      <td>26.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0             7.0             0.270         0.36            20.7      0.045   \n",
       "1             6.3             0.300         0.34             1.6      0.049   \n",
       "2             8.1             0.280         0.40             6.9      0.050   \n",
       "3             7.2             0.230         0.32             8.5      0.058   \n",
       "4             7.2             0.230         0.32             8.5      0.058   \n",
       "..            ...               ...          ...             ...        ...   \n",
       "95            7.1             0.260         0.29            12.4      0.044   \n",
       "96            6.0             0.340         0.66            15.9      0.046   \n",
       "97            8.6             0.265         0.36             1.2      0.034   \n",
       "98            9.8             0.360         0.46            10.5      0.038   \n",
       "99            6.0             0.340         0.66            15.9      0.046   \n",
       "\n",
       "    free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                  45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                  14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                  30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                  47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                  47.0                 186.0   0.9956  3.19       0.40   \n",
       "..                  ...                   ...      ...   ...        ...   \n",
       "95                 62.0                 240.0   0.9969  3.04       0.42   \n",
       "96                 26.0                 164.0   0.9979  3.14       0.50   \n",
       "97                 15.0                  80.0   0.9913  2.95       0.36   \n",
       "98                  4.0                  83.0   0.9956  2.89       0.30   \n",
       "99                 26.0                 164.0   0.9979  3.14       0.50   \n",
       "\n",
       "    alcohol  quality  colour  \n",
       "0       8.8        6       0  \n",
       "1       9.5        6       0  \n",
       "2      10.1        6       0  \n",
       "3       9.9        6       0  \n",
       "4       9.9        6       0  \n",
       "..      ...      ...     ...  \n",
       "95      9.2        6       0  \n",
       "96      8.8        6       0  \n",
       "97     11.4        7       0  \n",
       "98     10.1        4       0  \n",
       "99      8.8        6       0  \n",
       "\n",
       "[100 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_r = pd.read_csv(\"D:/UWaterloo/ece657a/Assignment 2/winequality-red.csv\", sep=';')\n",
    "wine_r[\"colour\"]=1\n",
    "wine_w = pd.read_csv(\"D:/UWaterloo/ece657a/Assignment 2/winequality-white.csv\", sep=';')\n",
    "wine_w[\"colour\"]=0\n",
    "wine_raw = pd.concat([wine_w,wine_r], ignore_index=True)\n",
    "wine_raw.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc5ac9",
   "metadata": {},
   "source": [
    "## Applying PCA as a pre-processing step on wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58941262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.185179</td>\n",
       "      <td>3.529983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.247707</td>\n",
       "      <td>-0.553177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.380592</td>\n",
       "      <td>0.365447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.735882</td>\n",
       "      <td>0.929351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.735882</td>\n",
       "      <td>0.929351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>2.699833</td>\n",
       "      <td>-0.854172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>2.524458</td>\n",
       "      <td>-1.161039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>2.775507</td>\n",
       "      <td>-0.761733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>2.984356</td>\n",
       "      <td>-0.767021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>1.852698</td>\n",
       "      <td>-0.516246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PC1       PC2\n",
       "0    -2.185179  3.529983\n",
       "1    -0.247707 -0.553177\n",
       "2    -0.380592  0.365447\n",
       "3    -1.735882  0.929351\n",
       "4    -1.735882  0.929351\n",
       "...        ...       ...\n",
       "6492  2.699833 -0.854172\n",
       "6493  2.524458 -1.161039\n",
       "6494  2.775507 -0.761733\n",
       "6495  2.984356 -0.767021\n",
       "6496  1.852698 -0.516246\n",
       "\n",
       "[6497 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate indep and dep features\n",
    "X_wine1 = wine_raw.iloc[:, :-2]\n",
    "y_wine = wine_raw.iloc[:, -2]\n",
    "X_wine = pd.concat([X_wine1, wine_raw.iloc[:, -1]], axis=1)\n",
    "\n",
    "# Normalize dataset \n",
    "sc2 = StandardScaler()\n",
    "X_wine = sc2.fit_transform(X_wine)\n",
    "X_wine.shape, y_wine.shape\n",
    "\n",
    "# Apply PCA on wine dataset for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "wine_pca = pca.fit_transform(X_wine)\n",
    "wine_pca_df = pd.DataFrame(data=wine_pca, columns=['PC1', 'PC2'])\n",
    "wine_pca_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3b06cc",
   "metadata": {},
   "source": [
    "## Applying LDA as a pre-processing step on wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be6dfaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6497, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.752078</td>\n",
       "      <td>-1.466209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.445150</td>\n",
       "      <td>0.392049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.123015</td>\n",
       "      <td>0.911451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.288961</td>\n",
       "      <td>-0.721769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.288961</td>\n",
       "      <td>-0.721769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.512278</td>\n",
       "      <td>-0.224430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.514707</td>\n",
       "      <td>-0.597340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.231160</td>\n",
       "      <td>-0.831907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.630811</td>\n",
       "      <td>0.158871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.668993</td>\n",
       "      <td>-2.296580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1\n",
       "quality                    \n",
       "6        0.752078 -1.466209\n",
       "6        1.445150  0.392049\n",
       "6       -0.123015  0.911451\n",
       "6        0.288961 -0.721769\n",
       "6        0.288961 -0.721769\n",
       "...           ...       ...\n",
       "5        0.512278 -0.224430\n",
       "6       -0.514707 -0.597340\n",
       "6       -0.231160 -0.831907\n",
       "5        0.630811  0.158871\n",
       "6       -0.668993 -2.296580\n",
       "\n",
       "[6497 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply LDA on raw wine dataset\n",
    "X_wine_lda = X_wine\n",
    "y_wine_lda = y_wine\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_wine_lda = lda.fit(X_wine_lda, y_wine_lda).transform(X_wine_lda)\n",
    "wine_lda_df = pd.DataFrame(X_wine_lda, y_wine_lda)\n",
    "print(wine_lda_df.shape)\n",
    "wine_lda_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e13f2d",
   "metadata": {},
   "source": [
    "# Gradient Boosting on Abalone dataset\n",
    "### Printing Test accuracy for raw abalone dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d19a7677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6af1949b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.2428\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_abalone, y_abalone, test_size=0.2, random_state=42)\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=153, learning_rate=0.1, max_depth=8)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy score: {acc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b01e519",
   "metadata": {},
   "source": [
    "## Plotting confusion matrix for abalone raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82b0adc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.40      0.31      0.35        13\n",
      "           5       0.42      0.34      0.38        32\n",
      "           6       0.28      0.25      0.26        48\n",
      "           7       0.27      0.26      0.27        84\n",
      "           8       0.26      0.33      0.29        99\n",
      "           9       0.25      0.29      0.27       142\n",
      "          10       0.27      0.32      0.29       139\n",
      "          11       0.23      0.25      0.24        93\n",
      "          12       0.18      0.12      0.14        51\n",
      "          13       0.11      0.13      0.12        31\n",
      "          14       0.20      0.04      0.06        26\n",
      "          15       0.00      0.00      0.00        21\n",
      "          16       0.00      0.00      0.00        13\n",
      "          17       0.00      0.00      0.00         8\n",
      "          18       0.00      0.00      0.00        12\n",
      "          19       0.00      0.00      0.00         7\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.33      0.33      0.33         3\n",
      "          23       1.00      0.25      0.40         4\n",
      "          24       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.24       836\n",
      "   macro avg       0.18      0.14      0.15       836\n",
      "weighted avg       0.24      0.24      0.24       836\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  4  5  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  3  5 11  7  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  6 12 17  8  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  3 16 22 20 13  5  1  1  0  0  0  1  0  1  0  1  0  0  0  0]\n",
      " [ 0  0  0  1  3 15 33 28 11  4  2  0  0  0  0  0  0  0  0  0  2  0  0]\n",
      " [ 0  0  0  0  2  6 30 41 35 20  1  4  0  0  0  0  3  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  8 17 37 44 19  8  2  0  0  0  2  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  3  9 17 26 23  5  6  0  1  1  0  1  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  1  2  3  4 16 10  6  4  1  2  0  0  1  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  2  3  2  6  9  1  4  0  1  2  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  2  6  7  3  1  3  1  1  2  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  9  1  1  7  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  1  4  3  1  0  1  0  0  1  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  3  1  2  0  0  1  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  1  4  1  1  1  2  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  1  1  2  0  1  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  1  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  1  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  1  0  0  0  1  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "Training Score:  1.0\n",
      "Testing Score:  0.24282296650717702\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('Classification Report: \\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "gdb_train_acc = model.score(X_train, y_train) \n",
    "print('Training Score: ', gdb_train_acc)\n",
    "gdb_test_acc = model.score(X_test, y_test)\n",
    "print('Testing Score: ', gdb_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03054ee7",
   "metadata": {},
   "source": [
    "The accuracy on the abalone raw dataset using Gradient Boosting classifier is less than Random Forests when using similar parameters, possibly due to the effect of outliers. It takes longer to train with Gradient Boosting than Random Forests. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd5f007",
   "metadata": {},
   "source": [
    "Lack of strong linear relationships: Gradient boosting relies on creating ensembles of weak learners, which are typically decision trees, to model complex non-linear relationships between the input features and the target variable. \n",
    "However, if the input features do not exhibit strong linear relationships with the target variable, the decision trees may not be able to capture the complex non-linear relationships in the data.\n",
    "\n",
    "Insufficient number of features: The Abalone dataset contains only 8 input features, which may not be sufficient to capture all the complexity in the data. If the input features do not provide enough information to accurately predict the target variable, the model may not perform well.\n",
    "\n",
    "Overfitting: Gradient boosting can be prone to overfitting if the hyperparameters are not tuned properly. Overfitting occurs when the model learns to fit the training data too closely, which can lead to poor generalization performance on new, unseen data. This can happen if the model is too complex relative to the size of the training data, or if the learning rate is set too high, which causes the model to over-emphasize the contribution of individual trees.\n",
    "\n",
    "Randomness in the data: The Abalone dataset contains some randomness due to the nature of the abalone shells and the way they grow. This can make it difficult for any model to accurately predict the age of an abalone based solely on physical measurements, which may contribute to the poor performance of gradient boosting on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22926fb",
   "metadata": {},
   "source": [
    "## Changing the parameter: n_estimator=100, lr=0.1, and max depth 3 for raw abalone dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1775d78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.2548\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy score: {acc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6665617c",
   "metadata": {},
   "source": [
    "### priting the confusion matrix after changing the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0c4a948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.40      0.67      0.50         3\n",
      "           4       0.35      0.46      0.40        13\n",
      "           5       0.48      0.47      0.48        32\n",
      "           6       0.28      0.27      0.28        48\n",
      "           7       0.28      0.27      0.28        84\n",
      "           8       0.25      0.33      0.29        99\n",
      "           9       0.29      0.35      0.32       142\n",
      "          10       0.27      0.28      0.27       139\n",
      "          11       0.26      0.25      0.26        93\n",
      "          12       0.04      0.02      0.03        51\n",
      "          13       0.10      0.10      0.10        31\n",
      "          14       0.21      0.15      0.18        26\n",
      "          15       0.00      0.00      0.00        21\n",
      "          16       0.09      0.08      0.08        13\n",
      "          17       0.25      0.12      0.17         8\n",
      "          18       0.00      0.00      0.00        12\n",
      "          19       0.00      0.00      0.00         7\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         3\n",
      "          23       0.00      0.00      0.00         4\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.25       836\n",
      "   macro avg       0.15      0.17      0.16       836\n",
      "weighted avg       0.24      0.25      0.25       836\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  6  4  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  8 15  5  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  6 13 20  5  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  5 19 23 24  9  1  0  0  0  0  0  1  0  1  0  1  0  0  0  0  0]\n",
      " [ 0  0  1  2 15 33 35  9  0  1  0  0  1  1  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  3 10 29 49 35  9  3  1  2  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  4 23 29 39 21  8  3  1  4  2  0  1  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  5  6 19 27 23  4  5  2  0  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  6  6 13 12  1  4  4  1  1  0  0  0  1  0  0  0  1  0]\n",
      " [ 0  0  0  1  1  2  3  7  7  3  3  0  2  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  2  9  2  5  0  2  4  0  1  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  3  6  1  1  4  3  0  1  0  0  0  1  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  1  2  2  1  1  1  1  0  0  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  1  1  2  1  0  1  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  2  1  3  2  2  0  1  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  1  1  2  0  0  0  0  0  0  1  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  2  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  1  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  1  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  1  0  1  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "Training Score:  0.6917090691409757\n",
      "Testing Score:  0.25478468899521534\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('Classification Report: \\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "gdb_train_acc = model.score(X_train, y_train) \n",
    "print('Training Score: ', gdb_train_acc)\n",
    "gdb_test_acc = model.score(X_test, y_test)\n",
    "print('Testing Score: ', gdb_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b26cc41",
   "metadata": {},
   "source": [
    "Upon using more optimum parameters for Gradient Boosting, the accuracy increases. This low accuracy may be due to the fact that the features are highly correlated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84ebbcc",
   "metadata": {},
   "source": [
    "# Gradient Boosting on Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2315bf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.5992\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_wine, y_wine, test_size=0.2, random_state=42)\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.5, max_depth=3)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy score: {acc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef33a8",
   "metadata": {},
   "source": [
    "The accuracy of Gradient boosting on the wine - raw dataset is more than that of Random forests and this may be due to the fact that the dataset has outliers and is not balanced. When the dataset contains imbalanced classes, Random Forests may produce biased predictions towards the majority class, as each tree is built independently and can be influenced by the class imbalance, while Gradient Boosting Classifier can adjust the weights of the samples to balance the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16b2935",
   "metadata": {},
   "source": [
    "# Gradient Boosting on Abalone - PCA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f8747f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.1148\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(abalone_pca, y_abalone, test_size=0.2, random_state=42)\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.5, max_depth=3)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy score: {acc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df42ba9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.29      0.15      0.20        13\n",
      "           5       0.04      0.03      0.03        32\n",
      "           6       0.05      0.04      0.05        48\n",
      "           7       0.00      0.00      0.00        84\n",
      "           8       0.10      0.01      0.02        99\n",
      "           9       0.10      0.06      0.07       142\n",
      "          10       0.18      0.54      0.27       139\n",
      "          11       0.00      0.00      0.00        93\n",
      "          12       0.25      0.02      0.04        51\n",
      "          13       0.04      0.06      0.05        31\n",
      "          14       0.00      0.00      0.00        26\n",
      "          15       0.00      0.00      0.00        21\n",
      "          16       0.03      0.15      0.05        13\n",
      "          17       0.00      0.00      0.00         8\n",
      "          18       0.03      0.17      0.05        12\n",
      "          19       0.00      0.00      0.00         7\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         3\n",
      "          23       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.11       836\n",
      "   macro avg       0.05      0.06      0.04       836\n",
      "weighted avg       0.08      0.11      0.07       836\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  1  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  1  0  0  0  1 28  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  6  2  0  1 16 20  0  0  2  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0 11  9  0  2 26 28  0  1  2  0  0  0  0  5  0  0  0  0  0]\n",
      " [ 0  0  0  8  3  1 15 42  0  0 18  0  0  1  0 11  0  0  0  0  0]\n",
      " [ 0  0  6  6 14  3  8 79  0  1  8  0  0  2  0 15  0  0  0  0  0]\n",
      " [ 0  0  2  3 15  1  7 75  0  1 10  0  0 13  0 11  0  0  1  0  0]\n",
      " [ 0  0  1  3 18  1  4 39  0  0  0  0  0 19  0  6  0  0  2  0  0]\n",
      " [ 0  0  0  3  4  1  2 26  0  1  1  0  0  9  0  4  0  0  0  0  0]\n",
      " [ 0  0  0  0  2  0  3 16  0  0  2  0  0  6  0  2  0  0  0  0  0]\n",
      " [ 0  0  0  1  1  0  0 12  0  0  3  0  0  4  0  5  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0 16  0  0  0  0  0  2  0  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  9  0  0  1  0  0  2  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  4  0  0  1  0  0  3  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  3  0  0  7  0  0  0  0  0  0  0  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  4  0  0  0  0  0  3  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  2  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  1  0  0  2  0  0  1  0  0  0  0  0  0  0  0  0  0]]\n",
      "Training Score:  0.10356180784196349\n",
      "Testing Score:  0.11483253588516747\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('Classification Report: \\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "gdb_train_acc = model.score(X_train, y_train) \n",
    "print('Training Score: ', gdb_train_acc)\n",
    "gdb_test_acc = model.score(X_test, y_test)\n",
    "print('Testing Score: ', gdb_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f09ad76",
   "metadata": {},
   "source": [
    "The accuracy on PCA dataset upon using Gradient Boosting is lesser than Random forests. Overall it can be seen that PCA hurts the performance of a tree boosting classifier as data has been lost while reducing the number of dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef09818",
   "metadata": {},
   "source": [
    "# Gradient Boosting on Wine - PCA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93884daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.5400\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(wine_pca, y_wine, test_size=0.2, random_state=42)\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.5, max_depth=3)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy score: {acc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7eb5362b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.32      0.22      0.26        46\n",
      "           5       0.57      0.56      0.57       420\n",
      "           6       0.56      0.63      0.59       579\n",
      "           7       0.50      0.38      0.43       221\n",
      "           8       0.35      0.25      0.29        32\n",
      "\n",
      "    accuracy                           0.54      1300\n",
      "   macro avg       0.38      0.34      0.36      1300\n",
      "weighted avg       0.54      0.54      0.54      1300\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  0   0   2   0   0   0]\n",
      " [  1  10  10  21   2   2]\n",
      " [  2  10 237 158  10   3]\n",
      " [  3   7 141 362  61   5]\n",
      " [  1   3  24 103  85   5]\n",
      " [  0   1   3   8  12   8]]\n",
      "Training Score:  0.8289397729459304\n",
      "Testing Score:  0.54\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('Classification Report: \\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "gdb_train_acc = model.score(X_train, y_train) \n",
    "print('Training Score: ', gdb_train_acc)\n",
    "gdb_test_acc = model.score(X_test, y_test)\n",
    "print('Testing Score: ', gdb_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fa2e54",
   "metadata": {},
   "source": [
    "The training score is 82% whereas the same classifer has a training score of approximately 70% on raw data without PCA reduction. So in this case, PCA helps in improving the accuracy but there is a considerable amount of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735735a5",
   "metadata": {},
   "source": [
    "# Gradient Boosting on Abalone - LDA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81677544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.2105\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_abalone_lda, y_abalone, test_size=0.2, random_state=42)\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.5, max_depth=3)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy score: {acc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08d011f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00        13\n",
      "           5       0.39      0.56      0.46        32\n",
      "           6       0.30      0.29      0.29        48\n",
      "           7       0.31      0.29      0.30        84\n",
      "           8       0.20      0.31      0.24        99\n",
      "           9       0.30      0.28      0.29       142\n",
      "          10       0.18      0.19      0.18       139\n",
      "          11       0.15      0.12      0.13        93\n",
      "          12       0.38      0.06      0.10        51\n",
      "          13       0.07      0.13      0.09        31\n",
      "          14       0.00      0.00      0.00        26\n",
      "          15       0.00      0.00      0.00        21\n",
      "          16       0.25      0.23      0.24        13\n",
      "          17       0.10      0.12      0.11         8\n",
      "          18       0.00      0.00      0.00        12\n",
      "          19       0.00      0.00      0.00         7\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         3\n",
      "          23       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.21       836\n",
      "   macro avg       0.12      0.12      0.12       836\n",
      "weighted avg       0.21      0.21      0.20       836\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 0  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  3 18  9  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  3  4 14 14  8  1  1  0  0  0  0  1  0  0  0  0  1  0  0  1]\n",
      " [ 0  0  5 12 24 32  9  0  2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  4 17 31 26 14  1  0  1  1  2  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  1  3 12 30 40 34 17  0  4  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  6 27 26 27 20  2 13  8  2  2  3  0  0  0  0  0  1]\n",
      " [ 0  0  1  0  2  8 21 31 11  1 10  0  4  2  1  0  0  1  0  0  0]\n",
      " [ 0  0  0  1  0  5  5 13  8  3  8  3  3  0  1  1  0  0  0  0  0]\n",
      " [ 0  0  0  1  1  2  2 13  3  0  4  1  2  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  4  1  7  3  1  4  0  1  2  1  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  3  1  6  3  0  6  1  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  2  0  0  5  0  3  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  1  1  1  0  1  0  0  1  1  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  2  1  2  2  0  2  0  0  1  1  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  1  0  2  1  0  1  1  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  2  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  1  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  1  0  1  0  0  1  0  0  0]]\n",
      "Training Score:  0.6240646513020054\n",
      "Testing Score:  0.21052631578947367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('Classification Report: \\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "gdb_train_acc = model.score(X_train, y_train) \n",
    "print('Training Score: ', gdb_train_acc)\n",
    "gdb_test_acc = model.score(X_test, y_test)\n",
    "print('Testing Score: ', gdb_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cbf374",
   "metadata": {},
   "source": [
    "Training score is high as when the dataset has a small number of samples, Gradient boosting can overfit and since most features in the abalone dataset is highly correlated, dimensionality reduction has a positive effect on efficient computation. But testing score is very low as there is considerable loss of data and Gradient boosting works better with more features. \n",
    "The mean accuracy using Random Forests is 0.27 whereas for Gradient boosting, it is lower. This is possible if there are too many outliers/high correlation in the dataset, which is true for this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf7e244",
   "metadata": {},
   "source": [
    "# Gradient Boosting on Wine - LDA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6cfc5999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.5531\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_wine_lda, y_wine, test_size=0.2, random_state=42)\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy score: {acc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "129a2746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.33      0.09      0.14        46\n",
      "           5       0.60      0.66      0.63       420\n",
      "           6       0.54      0.64      0.59       579\n",
      "           7       0.49      0.29      0.37       221\n",
      "           8       0.20      0.03      0.05        32\n",
      "\n",
      "    accuracy                           0.55      1300\n",
      "   macro avg       0.36      0.29      0.30      1300\n",
      "weighted avg       0.54      0.55      0.53      1300\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  0   0   2   0   0   0]\n",
      " [  0   4  26  15   1   0]\n",
      " [  2   4 279 131   4   0]\n",
      " [  1   3 152 370  49   4]\n",
      " [  2   1   5 148  65   0]\n",
      " [  0   0   0  18  13   1]]\n",
      "Training Score:  0.6492207042524534\n",
      "Testing Score:  0.553076923076923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('Classification Report: \\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "gdb_train_acc = model.score(X_train, y_train) \n",
    "print('Training Score: ', gdb_train_acc)\n",
    "gdb_test_acc = model.score(X_test, y_test)\n",
    "print('Testing Score: ', gdb_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e2d038",
   "metadata": {},
   "source": [
    "There is less overfitting in the training data after using LDA and Gradient boosting techniques. The test accuracy is also close but not very high. Compared to random forests, the accuracy is similar on Wine - LDA dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318e94e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
